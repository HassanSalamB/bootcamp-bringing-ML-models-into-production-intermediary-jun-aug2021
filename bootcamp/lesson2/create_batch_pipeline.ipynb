{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "This notebook is adapted from Microsoft Learning mslearn-dp100 \n",
    "\n",
    "Copyright (c) 2021 PyLadies Amsterdam, Alyona Galyeva"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create batch pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connect to your workspace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from azureml.core import Workspace\r\n",
    "ws = Workspace.from_config()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Provision inference compute"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll need a compute context for the pipeline, so we'll use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
    "\n",
    "Important: Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.core.compute_target import ComputeTargetException\r\n",
    "\r\n",
    "cluster_name = \"mlopsbootcamp\"\r\n",
    "\r\n",
    "try:\r\n",
    "    # Check for existing compute target\r\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
    "    print('Found existing cluster, use it.')\r\n",
    "except ComputeTargetException:\r\n",
    "    # If it doesn't already exist, create it\r\n",
    "    try:\r\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS2_v2', max_nodes=2)\r\n",
    "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
    "        inference_cluster.wait_for_completion(show_output=True)\r\n",
    "    except Exception as ex:\r\n",
    "        print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating............\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the Standard_DS11_v2 image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a pipeline for batch inferencing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we're ready to define the pipeline we'll use for batch inferencing. Our pipeline will need Python code to perform the batch inferencing, so let's create a folder where we can keep all the files used by the pipeline:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "# Create a folder for the experiment files\r\n",
    "experiment_folder = 'batch_pipeline'\r\n",
    "os.makedirs(experiment_folder, exist_ok=True)\r\n",
    "\r\n",
    "print(experiment_folder)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# let's check what models are registered in our workspace and get a path to our model of choice\r\n",
    "from azureml.core import Model\r\n",
    "model_list = Model.list(ws)\r\n",
    "model_path = Model.get_model_path('linear_regression', _workspace=ws)\r\n",
    "print(model_list, model_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Model(workspace=Workspace.create(name='mlops', subscription_id='ef7a4699-23c4-4d90-8b71-e5d1e63f9154', resource_group='mlops_bootcamp'), name=linear_regression, id=linear_regression:1, version=1, tags={}, properties={})] azureml-models\\linear_regression\\1\\linear_regression.pkl\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# let's load our model and take a look what's inside\r\n",
    "import joblib\r\n",
    "model = joblib.load(model_path)\r\n",
    "model\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('encoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [2, 3, 4])])),\n",
       "                ('rfecv',\n",
       "                 RFECV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                       estimator=LinearRegression(), n_jobs=-1,\n",
       "                       scoring='neg_mean_squared_error', verbose=2))])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "mini_batch = list()\r\n",
    "for (dirpath, dirnames, filenames) in os.walk(\"batch-data\"):\r\n",
    "    mini_batch += [os.path.join(dirpath, file) for file in filenames]\r\n",
    "for elem in mini_batch:\r\n",
    "    print(elem)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch-data\\1.csv\n",
      "batch-data\\10.csv\n",
      "batch-data\\100.csv\n",
      "batch-data\\101.csv\n",
      "batch-data\\102.csv\n",
      "batch-data\\103.csv\n",
      "batch-data\\104.csv\n",
      "batch-data\\105.csv\n",
      "batch-data\\106.csv\n",
      "batch-data\\107.csv\n",
      "batch-data\\108.csv\n",
      "batch-data\\109.csv\n",
      "batch-data\\11.csv\n",
      "batch-data\\110.csv\n",
      "batch-data\\111.csv\n",
      "batch-data\\112.csv\n",
      "batch-data\\113.csv\n",
      "batch-data\\114.csv\n",
      "batch-data\\115.csv\n",
      "batch-data\\116.csv\n",
      "batch-data\\117.csv\n",
      "batch-data\\118.csv\n",
      "batch-data\\119.csv\n",
      "batch-data\\12.csv\n",
      "batch-data\\120.csv\n",
      "batch-data\\121.csv\n",
      "batch-data\\122.csv\n",
      "batch-data\\123.csv\n",
      "batch-data\\124.csv\n",
      "batch-data\\125.csv\n",
      "batch-data\\126.csv\n",
      "batch-data\\127.csv\n",
      "batch-data\\128.csv\n",
      "batch-data\\129.csv\n",
      "batch-data\\13.csv\n",
      "batch-data\\130.csv\n",
      "batch-data\\131.csv\n",
      "batch-data\\132.csv\n",
      "batch-data\\133.csv\n",
      "batch-data\\134.csv\n",
      "batch-data\\135.csv\n",
      "batch-data\\136.csv\n",
      "batch-data\\137.csv\n",
      "batch-data\\138.csv\n",
      "batch-data\\139.csv\n",
      "batch-data\\14.csv\n",
      "batch-data\\140.csv\n",
      "batch-data\\141.csv\n",
      "batch-data\\142.csv\n",
      "batch-data\\143.csv\n",
      "batch-data\\144.csv\n",
      "batch-data\\145.csv\n",
      "batch-data\\146.csv\n",
      "batch-data\\147.csv\n",
      "batch-data\\148.csv\n",
      "batch-data\\149.csv\n",
      "batch-data\\15.csv\n",
      "batch-data\\150.csv\n",
      "batch-data\\151.csv\n",
      "batch-data\\152.csv\n",
      "batch-data\\153.csv\n",
      "batch-data\\154.csv\n",
      "batch-data\\155.csv\n",
      "batch-data\\156.csv\n",
      "batch-data\\157.csv\n",
      "batch-data\\158.csv\n",
      "batch-data\\159.csv\n",
      "batch-data\\16.csv\n",
      "batch-data\\160.csv\n",
      "batch-data\\161.csv\n",
      "batch-data\\162.csv\n",
      "batch-data\\163.csv\n",
      "batch-data\\164.csv\n",
      "batch-data\\165.csv\n",
      "batch-data\\166.csv\n",
      "batch-data\\167.csv\n",
      "batch-data\\168.csv\n",
      "batch-data\\17.csv\n",
      "batch-data\\18.csv\n",
      "batch-data\\19.csv\n",
      "batch-data\\2.csv\n",
      "batch-data\\20.csv\n",
      "batch-data\\21.csv\n",
      "batch-data\\22.csv\n",
      "batch-data\\23.csv\n",
      "batch-data\\24.csv\n",
      "batch-data\\25.csv\n",
      "batch-data\\26.csv\n",
      "batch-data\\27.csv\n",
      "batch-data\\28.csv\n",
      "batch-data\\29.csv\n",
      "batch-data\\3.csv\n",
      "batch-data\\30.csv\n",
      "batch-data\\31.csv\n",
      "batch-data\\32.csv\n",
      "batch-data\\33.csv\n",
      "batch-data\\34.csv\n",
      "batch-data\\35.csv\n",
      "batch-data\\36.csv\n",
      "batch-data\\37.csv\n",
      "batch-data\\38.csv\n",
      "batch-data\\39.csv\n",
      "batch-data\\4.csv\n",
      "batch-data\\40.csv\n",
      "batch-data\\41.csv\n",
      "batch-data\\42.csv\n",
      "batch-data\\43.csv\n",
      "batch-data\\44.csv\n",
      "batch-data\\45.csv\n",
      "batch-data\\46.csv\n",
      "batch-data\\47.csv\n",
      "batch-data\\48.csv\n",
      "batch-data\\49.csv\n",
      "batch-data\\5.csv\n",
      "batch-data\\50.csv\n",
      "batch-data\\51.csv\n",
      "batch-data\\52.csv\n",
      "batch-data\\53.csv\n",
      "batch-data\\54.csv\n",
      "batch-data\\55.csv\n",
      "batch-data\\56.csv\n",
      "batch-data\\57.csv\n",
      "batch-data\\58.csv\n",
      "batch-data\\59.csv\n",
      "batch-data\\6.csv\n",
      "batch-data\\60.csv\n",
      "batch-data\\61.csv\n",
      "batch-data\\62.csv\n",
      "batch-data\\63.csv\n",
      "batch-data\\64.csv\n",
      "batch-data\\65.csv\n",
      "batch-data\\66.csv\n",
      "batch-data\\67.csv\n",
      "batch-data\\68.csv\n",
      "batch-data\\69.csv\n",
      "batch-data\\7.csv\n",
      "batch-data\\70.csv\n",
      "batch-data\\71.csv\n",
      "batch-data\\72.csv\n",
      "batch-data\\73.csv\n",
      "batch-data\\74.csv\n",
      "batch-data\\75.csv\n",
      "batch-data\\76.csv\n",
      "batch-data\\77.csv\n",
      "batch-data\\78.csv\n",
      "batch-data\\79.csv\n",
      "batch-data\\8.csv\n",
      "batch-data\\80.csv\n",
      "batch-data\\81.csv\n",
      "batch-data\\82.csv\n",
      "batch-data\\83.csv\n",
      "batch-data\\84.csv\n",
      "batch-data\\85.csv\n",
      "batch-data\\86.csv\n",
      "batch-data\\87.csv\n",
      "batch-data\\88.csv\n",
      "batch-data\\89.csv\n",
      "batch-data\\9.csv\n",
      "batch-data\\90.csv\n",
      "batch-data\\91.csv\n",
      "batch-data\\92.csv\n",
      "batch-data\\93.csv\n",
      "batch-data\\94.csv\n",
      "batch-data\\95.csv\n",
      "batch-data\\96.csv\n",
      "batch-data\\97.csv\n",
      "batch-data\\98.csv\n",
      "batch-data\\99.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import numpy as np\r\n",
    "def run(mini_batch):\r\n",
    "    # This runs for each batch\r\n",
    "    resultList = []\r\n",
    "\r\n",
    "    # process each file in the batch\r\n",
    "    for f in mini_batch:\r\n",
    "        # Read comma-delimited data into an array\r\n",
    "        data = np.genfromtxt(f, delimiter=',')\r\n",
    "        # Reshape into a 2-dimensional array for model input\r\n",
    "        prediction = model.predict(data.reshape(1, -1))\r\n",
    "        # Append prediction to results\r\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
    "    return resultList"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "result = run(mini_batch)\r\n",
    "result"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['1.csv: 5755.163077175251',\n",
       " '10.csv: 7322.167496592862',\n",
       " '100.csv: 6116.004871469763',\n",
       " '101.csv: 6156.092754264967',\n",
       " '102.csv: 6294.968788850575',\n",
       " '103.csv: 6782.238254913661',\n",
       " '104.csv: 7326.4008013360335',\n",
       " '105.csv: 7730.640952776846',\n",
       " '106.csv: 7647.589687514605',\n",
       " '107.csv: 8235.684934829878',\n",
       " '108.csv: 8638.614801197713',\n",
       " '109.csv: 8831.621426435839',\n",
       " '11.csv: 7611.775571331817',\n",
       " '110.csv: 8926.95040271835',\n",
       " '111.csv: 8852.551606579724',\n",
       " '112.csv: 8894.393962729115',\n",
       " '113.csv: 8935.391041913888',\n",
       " '114.csv: 8828.09936453811',\n",
       " '115.csv: 8485.005655694782',\n",
       " '116.csv: 8322.560818863683',\n",
       " '117.csv: 8041.131147118628',\n",
       " '118.csv: 7829.522731946653',\n",
       " '119.csv: 7627.891908286288',\n",
       " '12.csv: 7895.639868551175',\n",
       " '120.csv: 7179.049536344058',\n",
       " '121.csv: 6863.960961958594',\n",
       " '122.csv: 6576.478453586541',\n",
       " '123.csv: 6323.083432511578',\n",
       " '124.csv: 6216.794025926226',\n",
       " '125.csv: 6111.832799093078',\n",
       " '126.csv: 6214.011215538499',\n",
       " '127.csv: 6309.964012929901',\n",
       " '128.csv: 6147.366565748184',\n",
       " '129.csv: 6333.541895717543',\n",
       " '13.csv: 8091.777025076891',\n",
       " '130.csv: 6731.414196423392',\n",
       " '131.csv: 6922.450999356121',\n",
       " '132.csv: 7207.922195128512',\n",
       " '133.csv: 7258.1038704068515',\n",
       " '134.csv: 7371.754451993839',\n",
       " '135.csv: 7121.845466996708',\n",
       " '136.csv: 7180.070270049474',\n",
       " '137.csv: 7236.40263714123',\n",
       " '138.csv: 7209.356693909619',\n",
       " '139.csv: 6873.690385419876',\n",
       " '14.csv: 8168.423175606583',\n",
       " '140.csv: 6837.9317188233845',\n",
       " '141.csv: 6461.277298377175',\n",
       " '142.csv: 6407.388994198834',\n",
       " '143.csv: 6258.102187916377',\n",
       " '144.csv: 5979.113819171272',\n",
       " '145.csv: 5729.482368059541',\n",
       " '146.csv: 5491.611363172738',\n",
       " '147.csv: 5231.447795304853',\n",
       " '148.csv: 5059.300186753393',\n",
       " '149.csv: 4995.878791519731',\n",
       " '15.csv: 8351.362811662631',\n",
       " '150.csv: 5022.640689569381',\n",
       " '151.csv: 5116.223738228702',\n",
       " '152.csv: 5037.192455732147',\n",
       " '153.csv: 5250.350812604948',\n",
       " '154.csv: 5570.90105421456',\n",
       " '155.csv: 5665.0030205573885',\n",
       " '156.csv: 5974.69482834476',\n",
       " '157.csv: 6055.78576385845',\n",
       " '158.csv: 6152.990934385248',\n",
       " '159.csv: 6130.6491908670205',\n",
       " '16.csv: 8623.519883284967',\n",
       " '160.csv: 6222.721543031442',\n",
       " '161.csv: 6136.081052859438',\n",
       " '162.csv: 6293.76881231738',\n",
       " '163.csv: 6023.010766844453',\n",
       " '164.csv: 6173.102714985721',\n",
       " '165.csv: 6057.360818350845',\n",
       " '166.csv: 6173.786002779468',\n",
       " '167.csv: 5991.751538403735',\n",
       " '168.csv: 5751.513939430152',\n",
       " '17.csv: 8793.909205569136',\n",
       " '18.csv: 8843.302293754099',\n",
       " '19.csv: 8577.48678667787',\n",
       " '2.csv: 5492.302008833268',\n",
       " '20.csv: 8167.394852150007',\n",
       " '21.csv: 7898.19967578259',\n",
       " '22.csv: 7716.602712779889',\n",
       " '23.csv: 7575.157882432389',\n",
       " '24.csv: 7027.923507060009',\n",
       " '25.csv: 6579.664548395548',\n",
       " '26.csv: 6243.870713192394',\n",
       " '27.csv: 6012.2330774893735',\n",
       " '28.csv: 5846.367842906499',\n",
       " '29.csv: 5792.930939126642',\n",
       " '3.csv: 5254.4533571845905',\n",
       " '30.csv: 5949.095473912439',\n",
       " '31.csv: 6348.140002933492',\n",
       " '32.csv: 6885.266804673302',\n",
       " '33.csv: 7629.381890455224',\n",
       " '34.csv: 8089.137208063544',\n",
       " '35.csv: 8379.359955393735',\n",
       " '36.csv: 8601.827723528626',\n",
       " '37.csv: 8755.972097386039',\n",
       " '38.csv: 8913.911599020194',\n",
       " '39.csv: 9080.009514337322',\n",
       " '4.csv: 5155.353692568117',\n",
       " '40.csv: 9273.190311039412',\n",
       " '41.csv: 9406.391492106533',\n",
       " '42.csv: 9452.016077890694',\n",
       " '43.csv: 9175.611206390608',\n",
       " '44.csv: 8783.458406062662',\n",
       " '45.csv: 8453.1061449905',\n",
       " '46.csv: 8322.778074106158',\n",
       " '47.csv: 8184.6163910441055',\n",
       " '48.csv: 7627.6533987862795',\n",
       " '49.csv: 7204.085552729076',\n",
       " '5.csv: 5107.025433179273',\n",
       " '50.csv: 6793.107197044584',\n",
       " '51.csv: 6551.34069212604',\n",
       " '52.csv: 6404.36509229563',\n",
       " '53.csv: 6340.744254753959',\n",
       " '54.csv: 6459.022886080021',\n",
       " '55.csv: 6948.7747713419',\n",
       " '56.csv: 7466.147736412294',\n",
       " '57.csv: 8076.950190513156',\n",
       " '58.csv: 8406.73584181277',\n",
       " '59.csv: 8696.735976361619',\n",
       " '6.csv: 5342.440111035173',\n",
       " '60.csv: 9031.42682835687',\n",
       " '61.csv: 9054.963642216077',\n",
       " '62.csv: 9200.679501625054',\n",
       " '63.csv: 8821.988395516186',\n",
       " '64.csv: 9048.783399561671',\n",
       " '65.csv: 9143.368480772995',\n",
       " '66.csv: 8894.631027262069',\n",
       " '67.csv: 7875.969017462149',\n",
       " '68.csv: 7775.443079945689',\n",
       " '69.csv: 7567.032354382364',\n",
       " '7.csv: 5745.35526822249',\n",
       " '70.csv: 7522.81019047692',\n",
       " '71.csv: 7330.1948357662795',\n",
       " '72.csv: 6827.389733869547',\n",
       " '73.csv: 6462.708121929806',\n",
       " '74.csv: 6106.834030622354',\n",
       " '75.csv: 5886.395153329472',\n",
       " '76.csv: 5759.568613400655',\n",
       " '77.csv: 5752.824209632626',\n",
       " '78.csv: 5913.538784658591',\n",
       " '79.csv: 6372.591340389113',\n",
       " '8.csv: 6231.544389387896',\n",
       " '80.csv: 6894.916427115272',\n",
       " '81.csv: 7554.340755046992',\n",
       " '82.csv: 8007.906731448241',\n",
       " '83.csv: 8172.354392913353',\n",
       " '84.csv: 8465.9008173332',\n",
       " '85.csv: 8686.051799146193',\n",
       " '86.csv: 8813.55669054521',\n",
       " '87.csv: 9002.485797512607',\n",
       " '88.csv: 9137.233791507657',\n",
       " '89.csv: 9301.409198019715',\n",
       " '9.csv: 6843.996768533587',\n",
       " '90.csv: 9238.814717314024',\n",
       " '91.csv: 8718.590059526468',\n",
       " '92.csv: 8333.642946937922',\n",
       " '93.csv: 8133.5809453170505',\n",
       " '94.csv: 7972.757500346989',\n",
       " '95.csv: 7829.588612512162',\n",
       " '96.csv: 7378.592955004892',\n",
       " '97.csv: 6925.937487746624',\n",
       " '98.csv: 6471.173393820379',\n",
       " '99.csv: 6292.36185386349']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll create a Python script to do the actual work, and save it in the pipeline folder:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%%writefile $experiment_folder/score.py\r\n",
    "# windows users\r\n",
    "# %%writefile $experiment_folder\\score.py\r\n",
    "\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "from azureml.core import Model\r\n",
    "import joblib\r\n",
    "\r\n",
    "def init():\r\n",
    "    # Runs when the pipeline step is initialized\r\n",
    "    global model\r\n",
    "\r\n",
    "    # load the model\r\n",
    "    model_path = Model.get_model_path('linear_regression')\r\n",
    "    model = joblib.load(model_path)\r\n",
    "\r\n",
    "def run(mini_batch):\r\n",
    "    # This runs for each batch\r\n",
    "    resultList = []\r\n",
    "\r\n",
    "    # process each file in the batch\r\n",
    "    for f in mini_batch:\r\n",
    "        # Read comma-delimited data into an array\r\n",
    "        data = np.genfromtxt(f, delimiter=',')\r\n",
    "        # Reshape into a 2-dimensional array for model input\r\n",
    "        prediction = model.predict(data.reshape(1, -1))\r\n",
    "        # Append prediction to results\r\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
    "    return resultList"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing batch_pipeline/score.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pipeline will need an environment in which to run, so we'll create a Conda specification that includes the packages that the code uses."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "%%writefile $experiment_folder/batch_environment.yml\r\n",
    "# windows users\r\n",
    "# %%writefile $experiment_folder\\batch_environment.yml\r\n",
    "name: batch_environment\r\n",
    "dependencies:\r\n",
    "- python=3.8\r\n",
    "- numpy\r\n",
    "- pandas\r\n",
    "- scikit-learn\r\n",
    "- pip:\r\n",
    "  - azureml-core"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing batch_pipeline/batch_environment.yml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we'll define a run context that includes the Conda environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from azureml.core import Environment\r\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
    "\r\n",
    "# Create an Environment for the experiment\r\n",
    "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\r\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
    "print('Configuration ready.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a ParallelRunStep, which enables the batch data to be processed in parallel and the results collated in a single output file named parallel_run_step.txt."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from datetime import datetime\r\n",
    "\r\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
    "from azureml.data import OutputFileDatasetConfig\r\n",
    "from azureml.core.runconfig import DockerConfiguration\r\n",
    "\r\n",
    "# # Get the batch dataset for input\r\n",
    "batch_data_set = ws.datasets['batch-data']\r\n",
    "\r\n",
    "# Set the output location\r\n",
    "default_ds = ws.get_default_datastore()\r\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\r\n",
    "\r\n",
    "# Define the parallel run step step configuration\r\n",
    "parallel_run_config = ParallelRunConfig(\r\n",
    "    source_directory=experiment_folder,\r\n",
    "    entry_script=\"score.py\",\r\n",
    "    mini_batch_size=\"5\",\r\n",
    "    error_threshold=10,\r\n",
    "    output_action=\"append_row\",\r\n",
    "    environment=batch_env,\r\n",
    "    compute_target=inference_cluster,\r\n",
    "    node_count=2)\r\n",
    "\r\n",
    "parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\r\n",
    "\r\n",
    "# Create the parallel run step\r\n",
    "parallelrun_step = ParallelRunStep(\r\n",
    "    name=parallel_step_name,\r\n",
    "    parallel_run_config=parallel_run_config,\r\n",
    "    inputs=[batch_data_set.as_named_input('batch_data')],\r\n",
    "    output=output_dir,\r\n",
    "    arguments=[],\r\n",
    "    allow_reuse=True\r\n",
    ")\r\n",
    "\r\n",
    "print('Steps defined')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Steps defined\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\madmin\\.conda\\envs\\environment\\lib\\site-packages\\azureml\\pipeline\\core\\_parallel_run_step_base.py:591: UserWarning: \n",
      "ParallelRunStep requires azureml-dataset-runtime[fuse] for file dataset.\n",
      "Please add relevant package in CondaDependencies.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's time to put the step into a pipeline, and run it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from azureml.core import Experiment\r\n",
    "from azureml.pipeline.core import Pipeline\r\n",
    "\r\n",
    "# Create the pipeline\r\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
    "\r\n",
    "# Run the pipeline as an experiment\r\n",
    "pipeline_run = Experiment(ws, 'nyc-energy-demand-batch').submit(pipeline)\r\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step batchscoring-202107292226 [2ad45cf8][e66ec14f-d422-4fbc-a331-f819cd647bcb], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 76cc9437-e4e8-42a8-bb5a-1e2d12c216d8\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/76cc9437-e4e8-42a8-bb5a-1e2d12c216d8?wsid=/subscriptions/ef7a4699-23c4-4d90-8b71-e5d1e63f9154/resourcegroups/mlops_bootcamp/workspaces/mlops&tid=68f8eea7-5130-4b29-9992-e2106b0299b5\n",
      "PipelineRunId: 76cc9437-e4e8-42a8-bb5a-1e2d12c216d8\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/76cc9437-e4e8-42a8-bb5a-1e2d12c216d8?wsid=/subscriptions/ef7a4699-23c4-4d90-8b71-e5d1e63f9154/resourcegroups/mlops_bootcamp/workspaces/mlops&tid=68f8eea7-5130-4b29-9992-e2106b0299b5\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 21f37741-f9ed-4fb9-ad4e-cf55b955087a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/21f37741-f9ed-4fb9-ad4e-cf55b955087a?wsid=/subscriptions/ef7a4699-23c4-4d90-8b71-e5d1e63f9154/resourcegroups/mlops_bootcamp/workspaces/mlops&tid=68f8eea7-5130-4b29-9992-e2106b0299b5\n",
      "StepRun( batchscoring-202107292226 ) Status: NotStarted\n",
      "StepRun( batchscoring-202107292226 ) Status: Queued\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2021/07/29 20:27:58 Downloading source code...\n",
      "2021/07/29 20:27:59 Finished downloading source code\n",
      "2021/07/29 20:28:00 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/07/29 20:28:00 Successfully set up Docker network: acb_default_network\n",
      "2021/07/29 20:28:00 Setting up Docker configuration...\n",
      "2021/07/29 20:28:01 Successfully set up Docker configuration\n",
      "2021/07/29 20:28:01 Logging in to registry: 514fa2b999e04b9385371e52e7264f5f.azurecr.io\n",
      "2021/07/29 20:28:02 Successfully logged into 514fa2b999e04b9385371e52e7264f5f.azurecr.io\n",
      "2021/07/29 20:28:02 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/07/29 20:28:02 Scanning for dependencies...\n",
      "2021/07/29 20:28:03 Successfully scanned dependencies\n",
      "2021/07/29 20:28:03 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "4bbfd2c87b75: Pulling fs layer\n",
      "d2e110be24e1: Pulling fs layer\n",
      "889a7173dcfe: Pulling fs layer\n",
      "7a7a145ebf57: Pulling fs layer\n",
      "1ae81884420d: Pulling fs layer\n",
      "fcdf07e25452: Pulling fs layer\n",
      "95262654cd7f: Pulling fs layer\n",
      "520cb0fab4f5: Pulling fs layer\n",
      "00c1c086d027: Pulling fs layer\n",
      "282c4a3b6fb6: Pulling fs layer\n",
      "f4201c7ca826: Pulling fs layer\n",
      "7a7a145ebf57: Waiting\n",
      "1ae81884420d: Waiting\n",
      "fcdf07e25452: Waiting\n",
      "95262654cd7f: Waiting\n",
      "00c1c086d027: Waiting\n",
      "282c4a3b6fb6: Waiting\n",
      "f4201c7ca826: Waiting\n",
      "520cb0fab4f5: Waiting\n",
      "889a7173dcfe: Verifying Checksum\n",
      "889a7173dcfe: Download complete\n",
      "d2e110be24e1: Verifying Checksum\n",
      "d2e110be24e1: Download complete\n",
      "4bbfd2c87b75: Verifying Checksum\n",
      "4bbfd2c87b75: Download complete\n",
      "fcdf07e25452: Verifying Checksum\n",
      "fcdf07e25452: Download complete\n",
      "4bbfd2c87b75: Pull complete\n",
      "StepRun( batchscoring-202107292226 ) Status: Running\n",
      "d2e110be24e1: Pull complete\n",
      "889a7173dcfe: Pull complete\n",
      "1ae81884420d: Verifying Checksum\n",
      "1ae81884420d: Download complete\n",
      "520cb0fab4f5: Verifying Checksum\n",
      "520cb0fab4f5: Download complete\n",
      "95262654cd7f: Verifying Checksum\n",
      "95262654cd7f: Download complete\n",
      "00c1c086d027: Verifying Checksum\n",
      "00c1c086d027: Download complete\n",
      "282c4a3b6fb6: Verifying Checksum\n",
      "282c4a3b6fb6: Download complete\n",
      "f4201c7ca826: Verifying Checksum\n",
      "f4201c7ca826: Download complete\n",
      "7a7a145ebf57: Verifying Checksum\n",
      "7a7a145ebf57: Download complete\n",
      "7a7a145ebf57: Pull complete\n",
      "1ae81884420d: Pull complete\n",
      "fcdf07e25452: Pull complete\n",
      "95262654cd7f: Pull complete\n",
      "520cb0fab4f5: Pull complete\n",
      "00c1c086d027: Pull complete\n",
      "282c4a3b6fb6: Pull complete\n",
      "f4201c7ca826: Pull complete\n",
      "Digest: sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      " ---> 6ba46986c29e\n",
      "Step 2/18 : USER root\n",
      " ---> Running in 2dd6a8f9cde3\n",
      "Removing intermediate container 2dd6a8f9cde3\n",
      " ---> bd4d3fb2c70e\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in a286f6790611\n",
      "Removing intermediate container a286f6790611\n",
      " ---> 3d72ad2cc5e2\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in 2fa08b8587d6\n",
      "Removing intermediate container 2fa08b8587d6\n",
      " ---> f6ab0d1f2c76\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> ae3bcde1a6a1\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 8397bf35c68a\n",
      "Removing intermediate container 8397bf35c68a\n",
      " ---> 5ecc408e2d3a\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 0a40a533e333\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in cb8e5982b1a8\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2021.5.30    | 138 KB    |            |   0% \n",
      "certifi-2021.5.30    | 138 KB    | ########## | 100% \n",
      "\n",
      "ncurses-6.2          | 817 KB    |            |   0% \n",
      "ncurses-6.2          | 817 KB    | ########## | 100% \n",
      "ncurses-6.2          | 817 KB    | ########## | 100% \n",
      "\n",
      "ld_impl_linux-64-2.3 | 586 KB    |            |   0% \n",
      "ld_impl_linux-64-2.3 | 586 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    |            |   0% \n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
      "\n",
      "numpy-base-1.20.3    | 4.5 MB    |            |   0% \n",
      "numpy-base-1.20.3    | 4.5 MB    | ########## | 100% \n",
      "numpy-base-1.20.3    | 4.5 MB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.2.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.5.0 | 22 KB     |            |   0% \n",
      "libgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n",
      "\n",
      "six-1.16.0           | 18 KB     |            |   0% \n",
      "six-1.16.0           | 18 KB     | ########## | 100% \n",
      "\n",
      "mkl-service-2.4.0    | 59 KB     |            |   0% \n",
      "mkl-service-2.4.0    | 59 KB     | ########## | 100% \n",
      "\n",
      "numexpr-2.7.3        | 188 KB    |            |   0% \n",
      "numexpr-2.7.3        | 188 KB    | ########## | 100% \n",
      "\n",
      "libgfortran4-7.5.0   | 995 KB    |            |   0% \n",
      "libgfortran4-7.5.0   | 995 KB    | ########## | 100% \n",
      "\n",
      "readline-8.1         | 362 KB    |            |   0% \n",
      "readline-8.1         | 362 KB    | ########## | 100% \n",
      "\n",
      "python-dateutil-2.8. | 233 KB    |            |   0% \n",
      "python-dateutil-2.8. | 233 KB    | ########## | 100% \n",
      "\n",
      "bottleneck-1.3.2     | 125 KB    |            |   0% \n",
      "bottleneck-1.3.2     | 125 KB    | ########## | 100% \n",
      "\n",
      "setuptools-52.0.0    | 714 KB    |            |   0% \n",
      "setuptools-52.0.0    | 714 KB    | ########## | 100% \n",
      "setuptools-52.0.0    | 714 KB    | ########## | 100% \n",
      "\n",
      "libffi-3.3           | 50 KB     |            |   0% \n",
      "libffi-3.3           | 50 KB     | ########## | 100% \n",
      "\n",
      "mkl_random-1.2.2     | 308 KB    |            |   0% \n",
      "mkl_random-1.2.2     | 308 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.0 MB    |            |   0% \n",
      "tk-8.6.10            | 3.0 MB    | ########## | 100% \n",
      "tk-8.6.10            | 3.0 MB    | ########## | 100% \n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "\n",
      "ca-certificates-2021 | 113 KB    |            |   0% \n",
      "ca-certificates-2021 | 113 KB    | ########## | 100% \n",
      "\n",
      "scikit-learn-0.24.2  | 5.4 MB    |            |   0% \n",
      "scikit-learn-0.24.2  | 5.4 MB    | ########## | 100% \n",
      "scikit-learn-0.24.2  | 5.4 MB    | ########## | 100% \n",
      "\n",
      "wheel-0.36.2         | 33 KB     |            |   0% \n",
      "wheel-0.36.2         | 33 KB     | ########## | 100% \n",
      "\n",
      "intel-openmp-2021.3. | 1.4 MB    |            |   0% \n",
      "intel-openmp-2021.3. | 1.4 MB    | ########## | 100% \n",
      "\n",
      "mkl-2021.3.0         | 141.2 MB  |            |   0% \n",
      "mkl-2021.3.0         | 141.2 MB  | 4          |   4% \n",
      "mkl-2021.3.0         | 141.2 MB  | 9          |   9% \n",
      "mkl-2021.3.0         | 141.2 MB  | #3         |  14% \n",
      "mkl-2021.3.0         | 141.2 MB  | #9         |  19% \n",
      "mkl-2021.3.0         | 141.2 MB  | ##5        |  25% \n",
      "mkl-2021.3.0         | 141.2 MB  | ###        |  31% \n",
      "mkl-2021.3.0         | 141.2 MB  | ###5       |  36% \n",
      "mkl-2021.3.0         | 141.2 MB  | ####1      |  41% \n",
      "mkl-2021.3.0         | 141.2 MB  | ####6      |  47% \n",
      "mkl-2021.3.0         | 141.2 MB  | #####2     |  53% \n",
      "mkl-2021.3.0         | 141.2 MB  | #####9     |  59% \n",
      "mkl-2021.3.0         | 141.2 MB  | ######4    |  65% \n",
      "mkl-2021.3.0         | 141.2 MB  | #######    |  71% \n",
      "mkl-2021.3.0         | 141.2 MB  | #######6   |  76% \n",
      "mkl-2021.3.0         | 141.2 MB  | ########2  |  83% \n",
      "mkl-2021.3.0         | 141.2 MB  | ########8  |  89% \n",
      "mkl-2021.3.0         | 141.2 MB  | #########5 |  95% \n",
      "mkl-2021.3.0         | 141.2 MB  | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 341 KB    |            |   0% \n",
      "xz-5.2.5             | 341 KB    | ########## | 100% \n",
      "\n",
      "python-3.8.10        | 57.7 MB   |            |   0% \n",
      "python-3.8.10        | 57.7 MB   | #1         |  12% \n",
      "python-3.8.10        | 57.7 MB   | ##4        |  25% \n",
      "python-3.8.10        | 57.7 MB   | ####       |  40% \n",
      "python-3.8.10        | 57.7 MB   | #####4     |  55% \n",
      "python-3.8.10        | 57.7 MB   | #######    |  70% \n",
      "python-3.8.10        | 57.7 MB   | ########5  |  85% \n",
      "python-3.8.10        | 57.7 MB   | #########8 |  99% \n",
      "python-3.8.10        | 57.7 MB   | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 103 KB    |            |   0% \n",
      "zlib-1.2.11          | 103 KB    | ########## | 100% \n",
      "\n",
      "pandas-1.3.0         | 9.6 MB    |            |   0% \n",
      "pandas-1.3.0         | 9.6 MB    | #####3     |  53% \n",
      "pandas-1.3.0         | 9.6 MB    | ########## | 100% \n",
      "pandas-1.3.0         | 9.6 MB    | ########## | 100% \n",
      "\n",
      "_openmp_mutex-4.5    | 22 KB     |            |   0% \n",
      "_openmp_mutex-4.5    | 22 KB     | ########## | 100% \n",
      "\n",
      "numpy-1.20.3         | 23 KB     |            |   0% \n",
      "numpy-1.20.3         | 23 KB     | ########## | 100% \n",
      "\n",
      "libgomp-9.3.0        | 311 KB    |            |   0% \n",
      "libgomp-9.3.0        | 311 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.3.0      | 4.8 MB    |            |   0% \n",
      "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
      "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.3.0        | 180 KB    |            |   0% \n",
      "mkl_fft-1.3.0        | 180 KB    | ########## | 100% \n",
      "\n",
      "scipy-1.6.2          | 15.6 MB   |            |   0% \n",
      "scipy-1.6.2          | 15.6 MB   | ####3      |  44% \n",
      "scipy-1.6.2          | 15.6 MB   | #########8 |  99% \n",
      "scipy-1.6.2          | 15.6 MB   | ########## | 100% \n",
      "\n",
      "sqlite-3.36.0        | 990 KB    |            |   0% \n",
      "sqlite-3.36.0        | 990 KB    | ########## | 100% \n",
      "\n",
      "pytz-2021.1          | 181 KB    |            |   0% \n",
      "pytz-2021.1          | 181 KB    | ########## | 100% \n",
      "pytz-2021.1          | 181 KB    | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "pip-21.1.3           | 1.8 MB    |            |   0% \n",
      "pip-21.1.3           | 1.8 MB    | ########## | 100% \n",
      "pip-21.1.3           | 1.8 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1k       | 2.5 MB    |            |   0% \n",
      "openssl-1.1.1k       | 2.5 MB    | ########## | 100% \n",
      "openssl-1.1.1k       | 2.5 MB    | ########## | 100% \n",
      "\n",
      "joblib-1.0.1         | 208 KB    |            |   0% \n",
      "joblib-1.0.1         | 208 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "    \n",
      "\n",
      "done\n",
      "Installing pip dependencies: ...working... Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.97odz6md.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-core\n",
      "  Downloading azureml_core-1.32.0-py3-none-any.whl (2.2 MB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205/lib/python3.8/site-packages (from azureml-core->-r /azureml-environment-setup/condaenv.97odz6md.requirements.txt (line 1)) (2.8.2)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pytz in /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205/lib/python3.8/site-packages (from azureml-core->-r /azureml-environment-setup/condaenv.97odz6md.requirements.txt (line 1)) (2021.1)\n",
      "Collecting docker<5.0.0\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
      "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-9.0.0-py2.py3-none-any.whl (312 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting contextlib2<1.0.0\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting ruamel.yaml<0.17.5,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting urllib3<=1.26.5,>=1.23\n",
      "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
      "Collecting requests<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-8.1.0-py2.py3-none-any.whl (796 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting azure-core<2.0.0,>=1.15.0\n",
      "  Downloading azure_core-1.16.0-py2.py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-containerregistry>=2.0.0->azureml-core->-r /azureml-environment-setup/condaenv.97odz6md.requirements.txt (line 1)) (1.16.0)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.6-cp38-cp38-manylinux1_x86_64.whl (411 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205/lib/python3.8/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core->-r /azureml-environment-setup/condaenv.97odz6md.requirements.txt (line 1)) (2021.5.30)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.3-py3-none-any.whl (35 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2\n",
      "  Downloading ruamel.yaml.clib-0.2.6-cp38-cp38-manylinux1_x86_64.whl (570 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: urllib3, pycparser, idna, charset-normalizer, requests, oauthlib, cffi, requests-oauthlib, PyJWT, isodate, cryptography, msrest, azure-core, adal, websocket-client, ruamel.yaml.clib, pyopenssl, pyasn1, msrestazure, jeepney, backports.weakref, azure-mgmt-core, azure-common, SecretStorage, ruamel.yaml, pathspec, ndg-httpsclient, jsonpickle, jmespath, docker, contextlib2, backports.tempfile, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, azureml-core\n",
      "Successfully installed PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 azure-common-1.1.27 azure-core-1.16.0 azure-graphrbac-0.61.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.1.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.0.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.32.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.6 charset-normalizer-2.0.3 contextlib2-0.6.0.post1 cryptography-3.4.7 docker-4.4.4 idna-3.2 isodate-0.6.0 jeepney-0.7.1 jmespath-0.10.0 jsonpickle-2.0.0 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.1 pathspec-0.9.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 requests-2.26.0 requests-oauthlib-1.3.0 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.6 urllib3-1.26.5 websocket-client-1.1.0\n",
      "\n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "\n",
      "Removing intermediate container cb8e5982b1a8\n",
      " ---> 27f1757b3175\n",
      "Step 9/18 : ENV PATH /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205/bin:$PATH\n",
      " ---> Running in fc3ef34c3059\n",
      "Removing intermediate container fc3ef34c3059\n",
      " ---> 051dbd24db86\n",
      "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 8578b103c769\n",
      "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 2ec13e32fccd\n",
      "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205\n",
      " ---> Running in 9aa9aa88b50b\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 9aa9aa88b50b\n",
      " ---> 8e9168ce88e6\n",
      "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205\n",
      " ---> Running in b50c161e8573\n",
      "Removing intermediate container b50c161e8573\n",
      " ---> 93ff21b616be\n",
      "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_0e994e8f6dddd5a9062958e2f1cf1205/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 31cc40b7027f\n",
      "Removing intermediate container 31cc40b7027f\n",
      " ---> 5c715613f821\n",
      "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 04d67baf9b7b\n",
      "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 8f2adb162b9a\n",
      "Removing intermediate container 8f2adb162b9a\n",
      " ---> 1c7528ddbe5b\n",
      "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in efacef7a1aac\n",
      "Removing intermediate container efacef7a1aac\n",
      " ---> 93901d0e8645\n",
      "Step 18/18 : CMD [\"bash\"]\n",
      " ---> Running in 797df37c48f3\n",
      "Removing intermediate container 797df37c48f3\n",
      " ---> 51ea67de173a\n",
      "Successfully built 51ea67de173a\n",
      "Successfully tagged 514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6:latest\n",
      "Successfully tagged 514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6:1\n",
      "2021/07/29 20:30:42 Successfully executed container: acb_step_0\n",
      "2021/07/29 20:30:42 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/07/29 20:30:42 Pushing image: 514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6:1, attempt 1\n",
      "The push refers to repository [514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6]\n",
      "e18ebc9bf80e: Preparing\n",
      "e12d0f10de4a: Preparing\n",
      "5145e913b771: Preparing\n",
      "ff36fb22331a: Preparing\n",
      "15a4515ddee5: Preparing\n",
      "7624f0a7e750: Preparing\n",
      "c46cbeb7adc8: Preparing\n",
      "4eb9c43fe3d9: Preparing\n",
      "56c7bdb68a5b: Preparing\n",
      "fe09032048fd: Preparing\n",
      "cbe733e9771d: Preparing\n",
      "74218ef6464a: Preparing\n",
      "5ba1f0778181: Preparing\n",
      "658e73e9fcdf: Preparing\n",
      "b48835f37b9c: Preparing\n",
      "a7c59d42f9e5: Preparing\n",
      "bb7a0d4412a3: Preparing\n",
      "5f08512fd434: Preparing\n",
      "c7bb31fc0e08: Preparing\n",
      "50858308da3d: Preparing\n",
      "7624f0a7e750: Waiting\n",
      "c46cbeb7adc8: Waiting\n",
      "4eb9c43fe3d9: Waiting\n",
      "56c7bdb68a5b: Waiting\n",
      "fe09032048fd: Waiting\n",
      "cbe733e9771d: Waiting\n",
      "74218ef6464a: Waiting\n",
      "5ba1f0778181: Waiting\n",
      "658e73e9fcdf: Waiting\n",
      "b48835f37b9c: Waiting\n",
      "a7c59d42f9e5: Waiting\n",
      "bb7a0d4412a3: Waiting\n",
      "5f08512fd434: Waiting\n",
      "c7bb31fc0e08: Waiting\n",
      "50858308da3d: Waiting\n",
      "e12d0f10de4a: Pushed\n",
      "5145e913b771: Pushed\n",
      "ff36fb22331a: Pushed\n",
      "e18ebc9bf80e: Pushed\n",
      "4eb9c43fe3d9: Pushed\n",
      "c46cbeb7adc8: Pushed\n",
      "7624f0a7e750: Pushed\n",
      "56c7bdb68a5b: Pushed\n",
      "fe09032048fd: Pushed\n",
      "cbe733e9771d: Pushed\n",
      "74218ef6464a: Pushed\n",
      "5ba1f0778181: Pushed\n",
      "\n",
      "a7c59d42f9e5: Pushed\n",
      "b48835f37b9c: Pushed\n",
      "5f08512fd434: Pushed\n",
      "c7bb31fc0e08: Pushed\n",
      "50858308da3d: Pushed\n",
      "658e73e9fcdf: Pushed\n",
      "\n",
      "bb7a0d4412a3: Pushed\n",
      "15a4515ddee5: Pushed\n",
      "1: digest: sha256:8583ae316e97cd16aeb0fc5e4009bad118410e03eede97c2507b899cdf2ecc3b size: 4514\n",
      "2021/07/29 20:32:41 Successfully pushed image: 514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6:1\n",
      "2021/07/29 20:32:41 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/07/29 20:32:41 Pushing image: 514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6:latest, attempt 1\n",
      "The push refers to repository [514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6]\n",
      "e18ebc9bf80e: Preparing\n",
      "e12d0f10de4a: Preparing\n",
      "5145e913b771: Preparing\n",
      "ff36fb22331a: Preparing\n",
      "15a4515ddee5: Preparing\n",
      "7624f0a7e750: Preparing\n",
      "c46cbeb7adc8: Preparing\n",
      "4eb9c43fe3d9: Preparing\n",
      "56c7bdb68a5b: Preparing\n",
      "fe09032048fd: Preparing\n",
      "cbe733e9771d: Preparing\n",
      "74218ef6464a: Preparing\n",
      "5ba1f0778181: Preparing\n",
      "658e73e9fcdf: Preparing\n",
      "b48835f37b9c: Preparing\n",
      "a7c59d42f9e5: Preparing\n",
      "bb7a0d4412a3: Preparing\n",
      "5f08512fd434: Preparing\n",
      "c7bb31fc0e08: Preparing\n",
      "50858308da3d: Preparing\n",
      "7624f0a7e750: Waiting\n",
      "5ba1f0778181: Waiting\n",
      "c46cbeb7adc8: Waiting\n",
      "4eb9c43fe3d9: Waiting\n",
      "56c7bdb68a5b: Waiting\n",
      "fe09032048fd: Waiting\n",
      "658e73e9fcdf: Waiting\n",
      "b48835f37b9c: Waiting\n",
      "cbe733e9771d: Waiting\n",
      "74218ef6464a: Waiting\n",
      "a7c59d42f9e5: Waiting\n",
      "bb7a0d4412a3: Waiting\n",
      "50858308da3d: Waiting\n",
      "5f08512fd434: Waiting\n",
      "c7bb31fc0e08: Waiting\n",
      "5145e913b771: Layer already exists\n",
      "e12d0f10de4a: Layer already exists\n",
      "15a4515ddee5: Layer already exists\n",
      "7624f0a7e750: Layer already exists\n",
      "56c7bdb68a5b: Layer already exists\n",
      "fe09032048fd: Layer already exists\n",
      "cbe733e9771d: Layer already exists\n",
      "74218ef6464a: Layer already exists\n",
      "c46cbeb7adc8: Layer already exists\n",
      "5ba1f0778181: Layer already exists\n",
      "ff36fb22331a: Layer already exists\n",
      "658e73e9fcdf: Layer already exists\n",
      "4eb9c43fe3d9: Layer already exists\n",
      "a7c59d42f9e5: Layer already exists\n",
      "bb7a0d4412a3: Layer already exists\n",
      "e18ebc9bf80e: Layer already exists\n",
      "c7bb31fc0e08: Layer already exists\n",
      "50858308da3d: Layer already exists\n",
      "b48835f37b9c: Layer already exists\n",
      "5f08512fd434: Layer already exists\n",
      "latest: digest: sha256:8583ae316e97cd16aeb0fc5e4009bad118410e03eede97c2507b899cdf2ecc3b size: 4514\n",
      "2021/07/29 20:32:44 Successfully pushed image: 514fa2b999e04b9385371e52e7264f5f.azurecr.io/azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6:latest\n",
      "2021/07/29 20:32:44 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 159.726758)\n",
      "2021/07/29 20:32:44 Populating digests for step ID: acb_step_0...\n",
      "2021/07/29 20:32:45 Successfully populated digests for step ID: acb_step_0\n",
      "2021/07/29 20:32:45 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 119.844354)\n",
      "2021/07/29 20:32:45 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.175758)\n",
      "2021/07/29 20:32:45 The following dependencies were found:\n",
      "2021/07/29 20:32:45 \n",
      "- image:\n",
      "    registry: 514fa2b999e04b9385371e52e7264f5f.azurecr.io\n",
      "    repository: azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6\n",
      "    tag: latest\n",
      "    digest: sha256:8583ae316e97cd16aeb0fc5e4009bad118410e03eede97c2507b899cdf2ecc3b\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210615.v1\n",
      "    digest: sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 514fa2b999e04b9385371e52e7264f5f.azurecr.io\n",
      "    repository: azureml/azureml_92ad9f3765fcbc655899d4b688dbf9e6\n",
      "    tag: \"1\"\n",
      "    digest: sha256:8583ae316e97cd16aeb0fc5e4009bad118410e03eede97c2507b899cdf2ecc3b\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210615.v1\n",
      "    digest: sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      "  git: {}\n",
      "\n",
      "Run ID: cb1 was successful after 4m49s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt\n",
      "========================================================================================================================\n",
      "2021-07-29T20:38:12Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=11437 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-07-29T20:38:13Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/mounts/workspaceblobstore\n",
      "2021-07-29T20:38:13Z The vmsize standard_ds2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-07-29T20:38:13Z Starting output-watcher...\n",
      "2021-07-29T20:38:13Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-07-29T20:38:15Z Executing 'Copy ACR Details file' on 10.0.0.7\n",
      "2021-07-29T20:38:15Z Executing 'Copy ACR Details file' on 10.0.0.6\n",
      "2021-07-29T20:38:15Z Copy ACR Details file succeeded on 10.0.0.6. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2021-07-29T20:38:16Z Copy ACR Details file succeeded on 10.0.0.7. Output: \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_fe4afc798de401edfb76dc27a38b1703\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "9e11d437728f: Pulling fs layer\n",
      "3506c910620f: Pulling fs layer\n",
      "afe6352c52c2: Pulling fs layer\n",
      "45d886309004: Pulling fs layer\n",
      "2ce19e789040: Pulling fs layer\n",
      "f2a2950e1ed4: Pulling fs layer\n",
      "33f6d5f2e001: Waiting\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "9e11d437728f: Waiting\n",
      "3506c910620f: Waiting\n",
      "afe6352c52c2: Waiting\n",
      "2ce19e789040: Waiting\n",
      "45d886309004: Waiting\n",
      "f2a2950e1ed4: Waiting\n",
      "fb52bde70123: Verifying Checksum\n",
      "fb52bde70123: Download complete\n",
      "64788f86be3f: Download complete\n",
      "33f6d5f2e001: Download complete\n",
      "92473f7ef455: Verifying Checksum\n",
      "92473f7ef455: Download complete\n",
      "fe519cf36537: Verifying Checksum\n",
      "fe519cf36537: Download complete\n",
      "58ff99196c15: Verifying Checksum\n",
      "58ff99196c15: Download complete\n",
      "eeb715f1b6ae: Verifying Checksum\n",
      "eeb715f1b6ae: Download complete\n",
      "6ee7c3767844: Verifying Checksum\n",
      "6ee7c3767844: Download complete\n",
      "9b13f06a8eff: Verifying Checksum\n",
      "9b13f06a8eff: Download complete\n",
      "62cfc3ccb8ab: Verifying Checksum\n",
      "62cfc3ccb8ab: Download complete\n",
      "4a7af9d757ee: Verifying Checksum\n",
      "4a7af9d757ee: Download complete\n",
      "9e11d437728f: Verifying Checksum\n",
      "9e11d437728f: Download complete\n",
      "afe6352c52c2: Verifying Checksum\n",
      "afe6352c52c2: Download complete\n",
      "45d886309004: Verifying Checksum\n",
      "45d886309004: Download complete\n",
      "2ce19e789040: Verifying Checksum\n",
      "2ce19e789040: Download complete\n",
      "f2a2950e1ed4: Verifying Checksum\n",
      "f2a2950e1ed4: Download complete\n",
      "2d4e93adbf58: Verifying Checksum\n",
      "2d4e93adbf58: Download complete\n",
      "3506c910620f: Verifying Checksum\n",
      "3506c910620f: Download complete\n",
      "92473f7ef455: Pull complete\n",
      "fb52bde70123: Pull complete\n",
      "64788f86be3f: Pull complete\n",
      "33f6d5f2e001: Pull complete\n",
      "eeb715f1b6ae: Pull complete\n",
      "fe519cf36537: Pull complete\n",
      "58ff99196c15: Pull complete\n",
      "9b13f06a8eff: Pull complete\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d.txt\n",
      "===============================================================================================================\n",
      "[2021-07-29T20:38:43.386815] Entering job preparation.\n",
      "[2021-07-29T20:38:44.102906] Starting job preparation.\n",
      "[2021-07-29T20:38:44.102946] Extracting the control code.\n",
      "[2021-07-29T20:38:44.103322] Starting extract_project.\n",
      "[2021-07-29T20:38:44.103416] Starting to extract zip file.\n",
      "[2021-07-29T20:38:44.125997] Finished extracting zip file.\n",
      "[2021-07-29T20:38:44.129440] Using urllib.request Python 3.0 or later\n",
      "[2021-07-29T20:38:44.129482] Start fetching snapshots.\n",
      "[2021-07-29T20:38:44.129601] Start fetching snapshot.\n",
      "[2021-07-29T20:38:44.129615] Retrieving project from snapshot: bf7ba796-5d9c-4106-b7de-fed0d95e4524\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 55\n",
      "[2021-07-29T20:38:44.519758] Finished fetching snapshot.\n",
      "[2021-07-29T20:38:44.519789] Start fetching snapshot.\n",
      "[2021-07-29T20:38:44.519818] Retrieving project from snapshot: f86ceba1-a7ff-4680-a48e-b5b1b1caf072\n",
      "[2021-07-29T20:38:54.692327] Finished fetching snapshot.\n",
      "[2021-07-29T20:38:54.692361] Finished fetching snapshots.\n",
      "[2021-07-29T20:38:54.692387] Finished extract_project.\n",
      "[2021-07-29T20:38:54.692462] Finished fetching and extracting the control code.\n",
      "[2021-07-29T20:38:54.700034] Start run_history_prep.\n",
      "[2021-07-29T20:38:54.707076] Job preparation is complete.\n",
      "[2021-07-29T20:38:54.707324] Entering Data Context Managers in Sidecar\n",
      "[2021-07-29T20:38:54.708161] Running Sidecar prep cmd...\n",
      "[2021-07-29T20:38:55.080678] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a\n",
      "[2021-07-29T20:38:55.081725] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt\n",
      "===============================================================================================================\n",
      "[2021-07-29T20:38:45.385806] Entering job preparation.\n",
      "[2021-07-29T20:38:46.075162] Starting job preparation.\n",
      "[2021-07-29T20:38:46.075193] Extracting the control code.\n",
      "[2021-07-29T20:38:46.075698] Starting extract_project.\n",
      "[2021-07-29T20:38:46.075794] Starting to extract zip file.\n",
      "[2021-07-29T20:38:46.106831] Finished extracting zip file.\n",
      "[2021-07-29T20:38:46.109804] Using urllib.request Python 3.0 or later\n",
      "[2021-07-29T20:38:46.109861] Start fetching snapshots.\n",
      "[2021-07-29T20:38:46.109896] Start fetching snapshot.\n",
      "[2021-07-29T20:38:46.109915] Retrieving project from snapshot: bf7ba796-5d9c-4106-b7de-fed0d95e4524\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 63\n",
      "[2021-07-29T20:38:46.260477] Finished fetching snapshot.\n",
      "[2021-07-29T20:38:46.260506] Start fetching snapshot.\n",
      "[2021-07-29T20:38:46.260516] Retrieving project from snapshot: f86ceba1-a7ff-4680-a48e-b5b1b1caf072\n",
      "[2021-07-29T20:38:54.698203] Finished fetching snapshot.\n",
      "[2021-07-29T20:38:54.698235] Finished fetching snapshots.\n",
      "[2021-07-29T20:38:54.698275] Finished extract_project.\n",
      "[2021-07-29T20:38:54.698373] Finished fetching and extracting the control code.\n",
      "[2021-07-29T20:38:54.704752] Start run_history_prep.\n",
      "[2021-07-29T20:38:54.710878] Job preparation is complete.\n",
      "[2021-07-29T20:38:54.711086] Entering Data Context Managers in Sidecar\n",
      "[2021-07-29T20:38:54.711837] Running Sidecar prep cmd...\n",
      "[2021-07-29T20:38:55.048778] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a\n",
      "[2021-07-29T20:38:55.049469] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.28.0 azureml-dataprep==2.16.0. Session id: a51eb5ab-c4a6-4649-8d22-9993fd3e3d1f. Run id: 21f37741-f9ed-4fb9-ad4e-cf55b955087a.\n",
      "Processing 'batch_data'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'batch-data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"c79eda19-3389-4975-8077-00a2c00fc097\",\n",
      "    \"name\": \"batch-data\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"batch data for nyc demand energy forecast\",\n",
      "    \"workspace\": \"Workspace.create(name='mlops', subscription_id='ef7a4699-23c4-4d90-8b71-e5d1e63f9154', resource_group='mlops_bootcamp')\"\n",
      "  }\n",
      "}\n",
      "Mounting batch_data to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/batch_data_c79eda19-3389-4975-8077-00a2c00fc097.\n",
      "Mounted batch_data to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/batch_data_c79eda19-3389-4975-8077-00a2c00fc097 as folder.\n",
      "Processing 'inferences'.\n",
      "Already registered authentication for run id: 21f37741-f9ed-4fb9-ad4e-cf55b955087a\n",
      "Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/inferences_workspaceblobstore.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set Dataset batch_data's target path to /mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/batch_data_c79eda19-3389-4975-8077-00a2c00fc097\n",
      "Set OutputDataset inferences's target path to /tmp/00576243-e6f1-4383-a518-683bfea27580\n",
      "[2021-07-29T20:39:10.695868] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-07-29T20:39:11.111208] Ran Sidecar prep cmd.\n",
      "[2021-07-29T20:39:11.111288] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/07/29 20:39:45 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/07/29 20:39:45 Version: 3.0.01664.0001 Branch: 2021-07-23 Commit: 3e1c760\n",
      "2021/07/29 20:39:45 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/info\n",
      "2021/07/29 20:39:45 Send process info logs to master server succeeded\n",
      "2021/07/29 20:39:45 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n",
      "2021/07/29 20:39:45 Send process info logs to master server succeeded\n",
      "[2021-07-29T20:39:45.986950] Entering context manager injector.\n",
      "[2021-07-29T20:39:46.421352] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'batch_data'])\n",
      "Script type = None\n",
      "[2021-07-29T20:39:46.425730] Entering Run History Context Manager.\n",
      "[2021-07-29T20:39:47.074024] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a\n",
      "[2021-07-29T20:39:47.074101] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'batch_data']\n",
      "[2021-07-29T20:39:47.074126] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/tmp/00576243-e6f1-4383-a518-683bfea27580', '--input_fds_0', 'batch_data']\n",
      "\n",
      "2021/07/29 20:39:50 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt\n",
      "===============================================================================================================\n",
      "[2021-07-29T20:41:04.183034] Entering job release\n",
      "[2021-07-29T20:41:05.058586] Starting job release\n",
      "[2021-07-29T20:41:05.059253] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 383\n",
      "[2021-07-29T20:41:05.059614] job release stage : upload_datastore starting...[2021-07-29T20:41:05.060291] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "\n",
      "[2021-07-29T20:41:05.062657] job release stage : execute_job_release starting...\n",
      "[2021-07-29T20:41:05.066270] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-07-29T20:41:05.074384] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-07-29T20:41:05.075044] Entering context manager injector.\n",
      "[2021-07-29T20:41:05.081521] job release stage : upload_datastore completed...\n",
      "[2021-07-29T20:41:05.191263] job release stage : execute_job_release completed...\n",
      "[2021-07-29T20:41:05.192852] job release stage : send_run_telemetry starting...\n",
      "[2021-07-29T20:41:05.211824] get vm size and vm region successfully.\n",
      "[2021-07-29T20:41:05.229283] get compute meta data successfully.\n",
      "Failed to upload compute record artifact, error_details=module 'azureml_globals' has no attribute 'compute_rcord_artifact_path'\n",
      "[2021-07-29T20:41:05.229382] upload compute record artifact successfully.\n",
      "[2021-07-29T20:41:05.229515] job release stage : send_run_telemetry completed...\n",
      "[2021-07-29T20:41:05.229837] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-07-29T20:41:05.230055] Running Sidecar release cmd...\n",
      "[2021-07-29T20:41:05.253029] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/batch_data_c79eda19-3389-4975-8077-00a2c00fc097.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/batch_data_c79eda19-3389-4975-8077-00a2c00fc097.\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/inferences_workspaceblobstore.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/inferences_workspaceblobstore: No such file or directory\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mlops/azureml/21f37741-f9ed-4fb9-ad4e-cf55b955087a/wd/inferences_workspaceblobstore.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-07-29T20:41:05.301403] Removing absolute paths from host...\n",
      "[2021-07-29T20:41:05.301595] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-07-29T20:41:06.056178] Ran Sidecar release cmd.\n",
      "[2021-07-29T20:41:06.056378] Job release is complete\n",
      "\n",
      "StepRun(batchscoring-202107292226) Execution Summary\n",
      "=====================================================\n",
      "StepRun( batchscoring-202107292226 ) Status: Finished\n",
      "{'runId': '21f37741-f9ed-4fb9-ad4e-cf55b955087a', 'target': 'mlopsbootcamp', 'status': 'Completed', 'startTimeUtc': '2021-07-29T20:38:09.909106Z', 'endTimeUtc': '2021-07-29T20:41:25.689313Z', 'properties': {'ContentSnapshotId': 'bf7ba796-5d9c-4106-b7de-fed0d95e4524', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'e66ec14f-d422-4fbc-a331-f819cd647bcb', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '2ad45cf8', 'azureml.pipelinerunid': '76cc9437-e4e8-42a8-bb5a-1e2d12c216d8', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': 'c79eda19-3389-4975-8077-00a2c00fc097'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'batch_data', 'mechanism': 'Mount'}}, {'dataset': {'id': '07962ca6-c532-43d4-90a7-b4b591c94897'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [{'identifier': {'savedId': '07962ca6-c532-43d4-90a7-b4b591c94897'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'inferences'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'dataset/21f37741-f9ed-4fb9-ad4e-cf55b955087a/inferences/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"07962ca6-c532-43d4-90a7-b4b591c94897\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='mlops', subscription_id='ef7a4699-23c4-4d90-8b71-e5d1e63f9154', resource_group='mlops_bootcamp')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'batch_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mlopsbootcamp', 'dataReferences': {}, 'data': {'batch_data': {'dataLocation': {'dataset': {'id': 'c79eda19-3389-4975-8077-00a2c00fc097', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'batch_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': '/tmp/00576243-e6f1-4383-a518-683bfea27580/', 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2021-07-29T20:27:47Z_24477ff0', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.8', 'numpy', 'pandas', 'scikit-learn', {'pip': ['azureml-core']}], 'name': 'azureml_0e994e8f6dddd5a9062958e2f1cf1205'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard'}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=PIEWboKiyXDIMwWEUhBFEAg1X0TI54PFFkSewRLJbDc%3D&st=2021-07-29T20%3A31%3A10Z&se=2021-07-30T04%3A41%3A10Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/55_azureml-execution-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt?sv=2019-02-02&sr=b&sig=oq2o2k06xq%2F5gcc0%2FSn3uugs5%2Fwkzh5ONc547FhCqpc%3D&st=2021-07-29T20%3A31%3A10Z&se=2021-07-30T04%3A41%3A10Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/55_azureml-execution-tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d.txt?sv=2019-02-02&sr=b&sig=K0TgQLbKNa7qyRoJjbxaAPtiL0Qdn1R1b1jxTmHTXhU%3D&st=2021-07-29T20%3A31%3A10Z&se=2021-07-30T04%3A41%3A10Z&sp=r', 'azureml-logs/65_job_prep-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/65_job_prep-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt?sv=2019-02-02&sr=b&sig=mCfVF2IADVo8IEGrCreIOlC4Wy%2B3k4dy3DCyeotJMHE%3D&st=2021-07-29T20%3A31%3A10Z&se=2021-07-30T04%3A41%3A10Z&sp=r', 'azureml-logs/65_job_prep-tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/65_job_prep-tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d.txt?sv=2019-02-02&sr=b&sig=T57xCVlW%2BJI59KAwzCh3ellezoDqHRdRd%2FJ2F9Sd3hU%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=jrHXirBB%2FslfV8KSxCTU4lrlDxWZCzt5Q1725dFA2Ko%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'azureml-logs/75_job_post-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/75_job_post-tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d.txt?sv=2019-02-02&sr=b&sig=2twrEupPCCi6V37IH72GtyFuzQ4Thg%2BTelqj2xU%2FA%2FE%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'azureml-logs/75_job_post-tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/75_job_post-tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d.txt?sv=2019-02-02&sr=b&sig=F6nN%2FSkhrK3xrf1f1Q77GU%2B238qmXlylPUl7frwXl4U%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=flGqjoK%2BIG1W8qB0w3QwT%2BvXPUBYs5%2Bvdfhg2JwmAYk%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=f1OsPQnrvxN3aTMz1NHOD3vfX11Me%2BftgOkTcUZk8Cw%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/101_azureml.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/101_azureml.log?sv=2019-02-02&sr=b&sig=xz0PCNZh5C1JltPxfiXF3kupqinzgFh4rWFIFuIqi6c%3D&st=2021-07-29T20%3A31%3A10Z&se=2021-07-30T04%3A41%3A10Z&sp=r', 'logs/azureml/149_azureml.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/149_azureml.log?sv=2019-02-02&sr=b&sig=S3NbvX0m%2F53pbo4iLLkbHvwg%2BazZo4uCwp3rgtU9HOw%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/87_azureml.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/87_azureml.log?sv=2019-02-02&sr=b&sig=kdtzQIx0UJtUTUuY8Df0u4gedmKiMAlfnehGwqxnmcs%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=38%2BF09nwoj7uKXZNgXYieFMy2M42eHnXMDDU9%2F4ssV0%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=gVzaeiZZ2PQi8uG1m7tb%2B%2FM70Zn1SBZpc55q8UfzN9I%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=rUy%2FepPZS7KFlaelR3OYd%2BmZXX3HKP9AE4I8qy2Ku0E%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=lI%2BinLwu4%2BjH1lb6wuKtGT0SQUrZMeimQZVcy9Ay2gY%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=3rDFWalGdbOwewJ5q2UQuOv40AO2DvtPXRhjpywFF6k%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/sidecar/tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d/all.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/sidecar/tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d/all.log?sv=2019-02-02&sr=b&sig=Sk0luAKOql6ssU5fuNuOG7jhvyoGNx4ZGa3ldkyP49U%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/sidecar/tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d/task.enter_contexts.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/sidecar/tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=L5i7VDwz9s427J1d0YCXZaKT8fLGnbL1BMbZ5ZhZLbM%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/sidecar/tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d/task.exit_contexts.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/sidecar/tvmps_4ccf38389c4c7a40098c9b876837ee7463183414abe8da3ccbb68468846bcbfd_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=Js%2Figh0VLF8CXrUA9Rt5N7uY9rv6KXd6L%2Fn%2Bgcl2KNU%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/sidecar/tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d/all.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/sidecar/tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d/all.log?sv=2019-02-02&sr=b&sig=G8FH%2FM5U5EN6Z9aqhupUxxTeVJFm7lTNgjte60GNC4Q%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/sidecar/tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d/task.enter_contexts.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/sidecar/tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=n%2FGekHwpb3CLq%2BiP77x8yL6MSmXpWYJT2HoRjTbLq3Y%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/sidecar/tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d/task.exit_contexts.log': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/sidecar/tvmps_c2523e6ebf9aa7a4c1977326a7783947c16f83133ff22eb84128a10ca95b8629_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=T6B6kds1HPjK80YSbuq1UIVL4fl3krxmbVBai9ETFFs%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=QGk2MrVBlPTMji%2BxRDyhX03hP008xNvm%2BrRswwLZ7oQ%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.21f37741-f9ed-4fb9-ad4e-cf55b955087a/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=mEabMA0d6MHgUJ2xIt0kUyKY4TmUsNV0CylfAA2JVfQ%3D&st=2021-07-29T20%3A31%3A11Z&se=2021-07-30T04%3A41%3A11Z&sp=r'}, 'submittedBy': 'Hassan Salam'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '76cc9437-e4e8-42a8-bb5a-1e2d12c216d8', 'status': 'Completed', 'startTimeUtc': '2021-07-29T20:26:45.200794Z', 'endTimeUtc': '2021-07-29T20:41:29.203727Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.76cc9437-e4e8-42a8-bb5a-1e2d12c216d8/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=o%2Fiq8vmp1QIud1sAMWBTv6yVS3VDLlIyI4eroEOXPog%3D&st=2021-07-29T20%3A17%3A36Z&se=2021-07-30T04%3A27%3A36Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.76cc9437-e4e8-42a8-bb5a-1e2d12c216d8/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=bpZl3KpSVvGMIRuyYhkdjMU4RJKrPRTJKjLuG1OOGKk%3D&st=2021-07-29T20%3A17%3A36Z&se=2021-07-30T04%3A27%3A36Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsstorage6b3a2110d0ba.blob.core.windows.net/azureml/ExperimentRun/dcid.76cc9437-e4e8-42a8-bb5a-1e2d12c216d8/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=KrZw37x8CyOLQfDHGeebmAiHe%2FgJO%2BYV%2BNZIGJVg1fk%3D&st=2021-07-29T20%3A17%3A36Z&se=2021-07-30T04%3A27%3A36Z&sp=r'}, 'submittedBy': 'Hassan Salam'}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import pandas as pd\r\n",
    "import shutil\r\n",
    "\r\n",
    "# Remove the local results folder if left over from a previous run\r\n",
    "shutil.rmtree('batch-results', ignore_errors=True)\r\n",
    "\r\n",
    "# Get the run for the first step and download its output\r\n",
    "prediction_run = next(pipeline_run.get_children())\r\n",
    "prediction_output = prediction_run.get_output_data('inferences')\r\n",
    "prediction_output.download(local_path='batch-results')\r\n",
    "\r\n",
    "# Traverse the folder hierarchy and find the results file\r\n",
    "for root, dirs, files in os.walk('batch-results'):\r\n",
    "    for file in files:\r\n",
    "        if file.endswith('parallel_run_step.txt'):\r\n",
    "            result_file = os.path.join(root,file)\r\n",
    "\r\n",
    "# cleanup output format\r\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
    "df.columns = [\"File\", \"Prediction\"]\r\n",
    "\r\n",
    "# Display the first 20 results\r\n",
    "df.head(20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       File   Prediction\n",
       "0     1.csv  5755.163077\n",
       "1    10.csv  7322.167497\n",
       "2   100.csv  6116.004871\n",
       "3   101.csv  6156.092754\n",
       "4   102.csv  6294.968789\n",
       "5   103.csv  6782.238255\n",
       "6   104.csv  7326.400801\n",
       "7   105.csv  7730.640953\n",
       "8   106.csv  7647.589688\n",
       "9   107.csv  8235.684935\n",
       "10  108.csv  8638.614801\n",
       "11  109.csv  8831.621426\n",
       "12   11.csv  7611.775571\n",
       "13  110.csv  8926.950403\n",
       "14  111.csv  8852.551607\n",
       "15  112.csv  8894.393963\n",
       "16  113.csv  8935.391042\n",
       "17  114.csv  8828.099365\n",
       "18  115.csv  8485.005656\n",
       "19  116.csv  8322.560819"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.csv</td>\n",
       "      <td>5755.163077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.csv</td>\n",
       "      <td>7322.167497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.csv</td>\n",
       "      <td>6116.004871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.csv</td>\n",
       "      <td>6156.092754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.csv</td>\n",
       "      <td>6294.968789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103.csv</td>\n",
       "      <td>6782.238255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104.csv</td>\n",
       "      <td>7326.400801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>105.csv</td>\n",
       "      <td>7730.640953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106.csv</td>\n",
       "      <td>7647.589688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>107.csv</td>\n",
       "      <td>8235.684935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.csv</td>\n",
       "      <td>8638.614801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>109.csv</td>\n",
       "      <td>8831.621426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.csv</td>\n",
       "      <td>7611.775571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>110.csv</td>\n",
       "      <td>8926.950403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>111.csv</td>\n",
       "      <td>8852.551607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>112.csv</td>\n",
       "      <td>8894.393963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>113.csv</td>\n",
       "      <td>8935.391042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>114.csv</td>\n",
       "      <td>8828.099365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>115.csv</td>\n",
       "      <td>8485.005656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>116.csv</td>\n",
       "      <td>8322.560819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Publish the Pipeline and use its REST Interface"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(name='Linear_regression_batch_prediction_pipeline',\r\n",
    "                                                   description='Batch scoring using linear regression model',\r\n",
    "                                                   version='1.0')\r\n",
    "\r\n",
    "published_pipeline"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(Name: Linear_regression_batch_prediction_pipeline,\n",
       "Id: 99322a55-ca44-4d4e-b63d-4d1bad6200fb,\n",
       "Status: Active,\n",
       "Endpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/ef7a4699-23c4-4d90-8b71-e5d1e63f9154/resourceGroups/mlops_bootcamp/providers/Microsoft.MachineLearningServices/workspaces/mlops/PipelineRuns/PipelineSubmit/99322a55-ca44-4d4e-b63d-4d1bad6200fb)"
      ],
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Linear_regression_batch_prediction_pipeline</td><td><a href=\"https://ml.azure.com/pipelines/99322a55-ca44-4d4e-b63d-4d1bad6200fb?wsid=/subscriptions/ef7a4699-23c4-4d90-8b71-e5d1e63f9154/resourcegroups/mlops_bootcamp/workspaces/mlops\" target=\"_blank\" rel=\"noopener\">99322a55-ca44-4d4e-b63d-4d1bad6200fb</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/ef7a4699-23c4-4d90-8b71-e5d1e63f9154/resourceGroups/mlops_bootcamp/providers/Microsoft.MachineLearningServices/workspaces/mlops/PipelineRuns/PipelineSubmit/99322a55-ca44-4d4e-b63d-4d1bad6200fb\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the published pipeline has an endpoint, which you can see in the Azure portal. You can also find it as a property of the published pipeline object:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "rest_endpoint = published_pipeline.endpoint\r\n",
    "print(rest_endpoint)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/ef7a4699-23c4-4d90-8b71-e5d1e63f9154/resourceGroups/mlops_bootcamp/providers/Microsoft.MachineLearningServices/workspaces/mlops/PipelineRuns/PipelineSubmit/99322a55-ca44-4d4e-b63d-4d1bad6200fb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\n",
    "\n",
    "Note: A real application would require a service principal with which to be authenticated."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
    "\r\n",
    "interactive_auth = InteractiveLoginAuthentication()\r\n",
    "auth_header = interactive_auth.get_authentication_header()\r\n",
    "print('Authentication header ready.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once published, you can use this endpoint to initiate a batch inferencing job, as shown in the following example code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import requests\r\n",
    "\r\n",
    "rest_endpoint = published_pipeline.endpoint\r\n",
    "response = requests.post(rest_endpoint, \r\n",
    "                         headers=auth_header, \r\n",
    "                         json={\"ExperimentName\": \"nyc-energy-demand-batch\"})\r\n",
    "run_id = response.json()[\"Id\"]\r\n",
    "run_id"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'d7037e38-9c63-4049-87dd-76a6b565bada'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also schedule the published pipeline to have it run automatically, as shown in the following example code:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\r\n",
    "\r\n",
    "weekly = ScheduleRecurrence(frequency='Week', interval=1)\r\n",
    "pipeline_schedule = Schedule.create(ws, name='Weekly Predictions',\r\n",
    "                                        description='batch inferencing',\r\n",
    "                                        pipeline_id=published_pipeline.id,\r\n",
    "                                        experiment_name='Batch_Prediction',\r\n",
    "                                        recurrence=weekly)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "IMPORTANT: Remove inference cluster if you do not plan to work on exercises immediately!!!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('environment': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "182e58e2cb227073aeee611a3282e9cc3089084ca159b9bc2e1f6cbe20a85f11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}